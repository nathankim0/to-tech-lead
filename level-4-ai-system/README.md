# Level 4: AI 시스템

## 소개

AI/ML 시스템은 2024-2025년 현재 모바일 앱 개발의 핵심 차별화 요소가 되었습니다. 이 레벨에서는 LLM(Large Language Model), RAG(Retrieval-Augmented Generation), Vector Database, Fine-tuning, MLOps까지 **AI 서비스를 프로덕션에 배포하고 운영하는 데 필요한 모든 것**을 다룹니다.

GPT-4, Claude, Gemini 같은 상용 LLM API를 단순히 호출하는 것을 넘어, **자사 데이터를 활용한 지능형 서비스를 설계하고 구축하는 방법**을 배웁니다.

---

## 학습 목표

이 레벨을 완료하면 다음을 할 수 있습니다:

- **AI 서비스 아키텍처 설계**: LLM 기반 서비스의 전체 아키텍처를 설계하고 구현할 수 있습니다
- **RAG 시스템 구축**: 자사 데이터(문서, FAQ, 상품 정보)를 활용한 AI 서비스를 설계할 수 있습니다
- **비용 효율적 운영**: 토큰 비용, 모델 선택, 캐싱 전략으로 비용을 최적화할 수 있습니다
- **모델 운영 자동화**: MLOps 파이프라인으로 모델 배포, 모니터링, 재학습을 자동화할 수 있습니다
- **모바일 AI 통합**: iOS/Android 앱에 AI 기능을 안정적으로 통합할 수 있습니다

---

## AI 시스템 전체 아키텍처

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                              AI 서비스 전체 아키텍처                             │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                 │
│  ┌───────────────────────────────────────────────────────────────────────────┐ │
│  │                          CLIENT LAYER (모바일/웹)                          │ │
│  │  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐      │ │
│  │  │   iOS App   │  │ Android App │  │   Web App   │  │  Admin CMS  │      │ │
│  │  │ (Core ML)   │  │  (ML Kit)   │  │  (React)    │  │             │      │ │
│  │  └──────┬──────┘  └──────┬──────┘  └──────┬──────┘  └──────┬──────┘      │ │
│  └─────────┼────────────────┼────────────────┼────────────────┼─────────────┘ │
│            │                │                │                │               │
│            └────────────────┴────────────────┴────────────────┘               │
│                                       │                                        │
│                                       ▼                                        │
│  ┌───────────────────────────────────────────────────────────────────────────┐ │
│  │                           API GATEWAY LAYER                                │ │
│  │  ┌───────────┐  ┌───────────┐  ┌───────────┐  ┌───────────┐              │ │
│  │  │   Auth    │  │   Rate    │  │  Request  │  │   Cost    │              │ │
│  │  │  (JWT)    │  │  Limiter  │  │   Cache   │  │  Tracker  │              │ │
│  │  └───────────┘  └───────────┘  └───────────┘  └───────────┘              │ │
│  └───────────────────────────────────┬───────────────────────────────────────┘ │
│                                       │                                        │
│                                       ▼                                        │
│  ┌───────────────────────────────────────────────────────────────────────────┐ │
│  │                            LLM GATEWAY LAYER                               │ │
│  │  ┌─────────────────────────────────────────────────────────────────────┐  │ │
│  │  │                         LLM Gateway                                  │  │ │
│  │  │  ┌───────────┐ ┌───────────┐ ┌───────────┐ ┌───────────┐           │  │ │
│  │  │  │  Model    │ │  Fallback │ │ Semantic  │ │Guardrails │           │  │ │
│  │  │  │  Router   │ │  Handler  │ │   Cache   │ │ (Safety)  │           │  │ │
│  │  │  └─────┬─────┘ └───────────┘ └───────────┘ └───────────┘           │  │ │
│  │  │        │                                                            │  │ │
│  │  │        ▼                                                            │  │ │
│  │  │  ┌───────────┐ ┌───────────┐ ┌───────────┐ ┌───────────┐           │  │ │
│  │  │  │  OpenAI   │ │ Anthropic │ │  Google   │ │Self-hosted│           │  │ │
│  │  │  │  GPT-4o   │ │ Claude 3.5│ │Gemini 1.5 │ │ Llama 3.2 │           │  │ │
│  │  │  └───────────┘ └───────────┘ └───────────┘ └───────────┘           │  │ │
│  │  └─────────────────────────────────────────────────────────────────────┘  │ │
│  └───────────────────────────────────┬───────────────────────────────────────┘ │
│                                       │                                        │
│                                       ▼                                        │
│  ┌───────────────────────────────────────────────────────────────────────────┐ │
│  │                         RAG PIPELINE LAYER                                 │ │
│  │                                                                           │ │
│  │    ┌─────────┐    ┌─────────┐    ┌─────────┐    ┌─────────┐             │ │
│  │    │  Query  │───▶│ Embed   │───▶│ Retrieve│───▶│ Re-rank │             │ │
│  │    │ Process │    │  Query  │    │  Top-K  │    │ Results │             │ │
│  │    └─────────┘    └────┬────┘    └────┬────┘    └────┬────┘             │ │
│  │                        │              │              │                   │ │
│  │                        ▼              │              ▼                   │ │
│  │    ┌─────────────────────────┐       │    ┌─────────────────────┐       │ │
│  │    │    Embedding Model      │       │    │    Prompt Builder   │       │ │
│  │    │ (text-embedding-3-small)│       │    │  + Context Injection│       │ │
│  │    └─────────────────────────┘       │    └──────────┬──────────┘       │ │
│  │                                      │               │                   │ │
│  │                                      ▼               ▼                   │ │
│  │                           ┌──────────────────────────────────┐          │ │
│  │                           │          Vector DB               │          │ │
│  │                           │  (Pinecone / Weaviate / pgvector)│          │ │
│  │                           └──────────────────────────────────┘          │ │
│  └───────────────────────────────────────────────────────────────────────────┘ │
│                                       │                                        │
│                                       ▼                                        │
│  ┌───────────────────────────────────────────────────────────────────────────┐ │
│  │                          DATA PIPELINE LAYER                               │ │
│  │                                                                           │ │
│  │    ┌───────────┐    ┌───────────┐    ┌───────────┐    ┌───────────┐     │ │
│  │    │  Source   │───▶│   ETL/    │───▶│  Chunk/   │───▶│  Embed/   │     │ │
│  │    │   Data    │    │ Transform │    │ Metadata  │    │  Index    │     │ │
│  │    └───────────┘    └───────────┘    └───────────┘    └───────────┘     │ │
│  │    (Docs, FAQ,       (Clean,         (512 tokens,     (Vector DB        │ │
│  │     Products)        Normalize)       Overlap)         Upsert)          │ │
│  └───────────────────────────────────────────────────────────────────────────┘ │
│                                       │                                        │
│                                       ▼                                        │
│  ┌───────────────────────────────────────────────────────────────────────────┐ │
│  │                            MLOps LAYER                                     │ │
│  │                                                                           │ │
│  │    ┌───────────┐    ┌───────────┐    ┌───────────┐    ┌───────────┐     │ │
│  │    │ Experiment│    │  Model    │    │ Drift     │    │  Alerting │     │ │
│  │    │ Tracking  │    │ Registry  │    │ Detection │    │  & Notify │     │ │
│  │    │ (MLflow)  │    │           │    │           │    │ (Slack)   │     │ │
│  │    └───────────┘    └───────────┘    └───────────┘    └───────────┘     │ │
│  │                                                                           │ │
│  │    ┌───────────┐    ┌───────────┐    ┌───────────┐    ┌───────────┐     │ │
│  │    │   A/B     │    │  Canary   │    │  Shadow   │    │   Auto    │     │ │
│  │    │   Test    │    │  Deploy   │    │   Mode    │    │ Retrain   │     │ │
│  │    └───────────┘    └───────────┘    └───────────┘    └───────────┘     │ │
│  └───────────────────────────────────────────────────────────────────────────┘ │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
```

---

## 학습 내용

| 순서 | 주제 | 설명 | 난이도 |
|:----:|------|------|:------:|
| 1 | [LLM 구조](./01-llm.md) | Transformer 아키텍처, Self-Attention, 토큰화, 주요 모델 비교 | 기초 |
| 2 | [RAG](./02-rag.md) | Retrieval-Augmented Generation 패턴, 청킹 전략, 검색 최적화 | 중급 |
| 3 | [Vector DB](./03-vector-db.md) | 벡터 검색 원리, HNSW, 임베딩, 주요 DB 비교 | 중급 |
| 4 | [Fine-tuning](./04-fine-tuning.md) | LoRA/QLoRA, DPO, PEFT, 학습 데이터 준비 | 고급 |
| 5 | [MLOps](./05-mlops.md) | 모델 배포, 모니터링, CI/CD, 드리프트 감지 | 고급 |

---

## 왜 모바일 개발자가 AI를 알아야 하는가?

```
2020년                              2024-2025년
┌─────────────────────┐            ┌────────────────────────────────────┐
│     모바일 앱       │            │           모바일 앱                │
│  ┌───────────────┐  │            │  ┌───────────┐  ┌───────────────┐  │
│  │      UI       │  │            │  │    UI     │  │  AI Features  │  │
│  └───────────────┘  │            │  │           │  │ ┌───────────┐ │  │
│  ┌───────────────┐  │            │  │           │  │ │ Chatbot   │ │  │
│  │   REST API    │  │   ─────▶   │  │           │  │ │ Search    │ │  │
│  └───────────────┘  │            │  │           │  │ │ Recommend │ │  │
│  ┌───────────────┐  │            │  └───────────┘  │ │ Summarize │ │  │
│  │   Database    │  │            │                  │ └───────────┘ │  │
│  └───────────────┘  │            │  ┌──────────────────────────────┐  │
└─────────────────────┘            │  │ On-device ML + Cloud LLM API │  │
                                   │  └──────────────────────────────┘  │
                                   └────────────────────────────────────┘

기존 모바일 개발자의 역할:              AI 시대 모바일 개발자의 역할:
- UI/UX 구현                          - AI 기능 통합 아키텍처 설계
- REST API 연동                       - LLM API 연동 및 최적화
- 로컬 DB 관리                        - On-device ML 모델 배포
                                      - AI 응답 스트리밍 처리
                                      - 오프라인/폴백 전략
                                      - 비용 최적화
```

### AI가 필수가 된 이유

1. **사용자 기대치 상승**: ChatGPT 경험 후, 사용자는 모든 앱에 지능형 기능을 기대
2. **경쟁 차별화**: AI 없는 앱은 "구식"으로 인식됨
3. **효율성 향상**: 자연어 검색, 자동 분류, 콘텐츠 생성으로 UX 대폭 개선
4. **On-device AI 성숙**: Core ML, ML Kit으로 오프라인에서도 AI 기능 제공 가능
5. **테크리드 역량**: AI 통합 아키텍처 설계는 시니어/리드 개발자의 핵심 역량

---

## 학습 로드맵

### Week 1: LLM 기초 (01-llm.md)

```
목표: LLM의 작동 원리와 API 사용법 이해

┌───────────────────────────────────────────────────────────────┐
│ Day 1-2: LLM 기초 이론                                        │
│ ├── Transformer 아키텍처 이해                                 │
│ ├── Self-Attention 메커니즘                                   │
│ └── 토큰화와 컨텍스트 윈도우                                  │
├───────────────────────────────────────────────────────────────┤
│ Day 3-4: 주요 모델 비교                                       │
│ ├── GPT-4o vs Claude 3.5 vs Gemini 1.5                       │
│ ├── 가격/성능/특징 비교                                       │
│ └── 유즈케이스별 모델 선택                                    │
├───────────────────────────────────────────────────────────────┤
│ Day 5-7: 실습                                                 │
│ ├── OpenAI API 호출 (Python/Swift/Kotlin)                    │
│ ├── 스트리밍 응답 처리                                        │
│ └── 토큰 카운팅과 비용 계산                                   │
└───────────────────────────────────────────────────────────────┘

핵심 질문:
- Temperature 0.0 vs 1.0의 차이는?
- Context Window를 효율적으로 사용하는 방법은?
- 프롬프트 인젝션 공격을 어떻게 방어하나?
```

### Week 2: RAG 시스템 (02-rag.md)

```
목표: 자사 데이터를 활용한 AI 응답 생성

┌───────────────────────────────────────────────────────────────┐
│ Day 1-2: RAG 개념                                             │
│ ├── RAG vs Fine-tuning 비교                                   │
│ ├── RAG 파이프라인 구조                                       │
│ └── 왜 RAG가 필요한가?                                        │
├───────────────────────────────────────────────────────────────┤
│ Day 3-4: 문서 처리                                            │
│ ├── 청킹 전략 (Fixed, Semantic, Recursive)                   │
│ ├── 메타데이터 추출                                           │
│ └── 임베딩 모델 선택                                          │
├───────────────────────────────────────────────────────────────┤
│ Day 5-7: 실습                                                 │
│ ├── LangChain으로 RAG 파이프라인 구축                        │
│ ├── Hybrid Search (BM25 + Vector)                            │
│ └── Re-ranking 적용                                           │
└───────────────────────────────────────────────────────────────┘

핵심 질문:
- 최적의 청크 크기는 어떻게 결정하나?
- 검색 결과가 없을 때 어떻게 처리하나?
- Multi-Query RAG는 언제 사용하나?
```

### Week 3: Vector DB (03-vector-db.md)

```
목표: 벡터 검색 시스템 구축 및 최적화

┌───────────────────────────────────────────────────────────────┐
│ Day 1-2: 벡터 검색 원리                                       │
│ ├── 임베딩과 유사도 검색                                      │
│ ├── HNSW 알고리즘                                             │
│ └── ANN vs KNN                                                │
├───────────────────────────────────────────────────────────────┤
│ Day 3-4: Vector DB 비교                                       │
│ ├── Pinecone, Weaviate, Milvus                               │
│ ├── pgvector (PostgreSQL)                                     │
│ └── 선택 기준: 규모, 비용, 기능                               │
├───────────────────────────────────────────────────────────────┤
│ Day 5-7: 실습                                                 │
│ ├── Pinecone 인덱스 생성 및 쿼리                             │
│ ├── 메타데이터 필터링                                         │
│ └── 성능 최적화 (배치, 네임스페이스)                          │
└───────────────────────────────────────────────────────────────┘

핵심 질문:
- 임베딩 차원 수는 어떻게 선택하나?
- Multi-tenant 환경에서 데이터를 어떻게 분리하나?
- Cosine vs Euclidean 유사도는 언제 사용하나?
```

### Week 4: Fine-tuning & MLOps (04-fine-tuning.md, 05-mlops.md)

```
목표: 커스텀 모델 학습과 프로덕션 운영

┌───────────────────────────────────────────────────────────────┐
│ Day 1-2: Fine-tuning 이론                                     │
│ ├── Full Fine-tuning vs LoRA vs QLoRA                        │
│ ├── 학습 데이터 준비                                          │
│ └── RAG vs Fine-tuning 선택 기준                              │
├───────────────────────────────────────────────────────────────┤
│ Day 3-4: Fine-tuning 실습                                     │
│ ├── OpenAI Fine-tuning API 사용                              │
│ ├── PEFT/LoRA 로컬 학습                                       │
│ └── DPO (Direct Preference Optimization)                      │
├───────────────────────────────────────────────────────────────┤
│ Day 5-7: MLOps                                                │
│ ├── 모델 레지스트리 (MLflow)                                  │
│ ├── CI/CD 파이프라인                                          │
│ ├── 모니터링 (Prometheus + Grafana)                          │
│ └── 드리프트 감지 및 재학습                                   │
└───────────────────────────────────────────────────────────────┘

핵심 질문:
- LoRA가 메모리를 절약하는 원리는?
- 과적합을 어떻게 방지하나?
- 모델 성능 저하를 어떻게 감지하나?
```

---

## 2024-2025 AI 트렌드

### 주요 모델 비교

| 모델 | 특징 | 가격 (1M 토큰) | 추천 용도 |
|------|------|---------------|-----------|
| **GPT-4o** | 범용 최강, 멀티모달 | $2.5 / $10 | 복잡한 추론, 코드 생성 |
| **Claude 3.5 Sonnet** | 긴 컨텍스트(200K), 안전성 | $3 / $15 | 문서 분석, 대화형 에이전트 |
| **Gemini 1.5 Pro** | 100만 토큰 컨텍스트 | $1.25 / $5 | 대용량 문서, 비디오 분석 |
| **GPT-4o-mini** | 빠르고 저렴 | $0.15 / $0.6 | 대량 처리, 분류 |
| **Claude 3.5 Haiku** | 초고속, 저비용 | $0.8 / $4 | 실시간 응답, 가벼운 태스크 |
| **Llama 3.2** | 오픈소스, Self-hosted | 인프라 비용만 | 프라이버시, 비용 최적화 |

### 핵심 트렌드

```
┌─────────────────────────────────────────────────────────────────┐
│                    2024-2025 AI 트렌드                           │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  1. Multi-modal AI                                              │
│     └── 텍스트 + 이미지 + 오디오 + 비디오 통합 처리             │
│                                                                 │
│  2. Agentic AI                                                  │
│     └── 자율적으로 도구 사용, 계획 수립, 실행하는 AI 에이전트   │
│                                                                 │
│  3. RAG 2.0                                                     │
│     └── Graph RAG, Multi-hop RAG, Self-RAG 등 고급 기법         │
│                                                                 │
│  4. 효율적 Fine-tuning                                          │
│     └── LoRA, QLoRA, DPO로 적은 데이터/비용으로 커스터마이징    │
│                                                                 │
│  5. LLM Observability                                           │
│     └── 환각 감지, 비용 추적, 품질 모니터링 도구 성숙           │
│                                                                 │
│  6. On-device LLM                                               │
│     └── Llama 3.2 1B/3B, Phi-3 mini 등 모바일/엣지 실행        │
│                                                                 │
│  7. Guardrails & Safety                                         │
│     └── 입출력 검증, 프롬프트 인젝션 방어, 편향 감지            │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## AI 학습 프롬프트 예시

### AI 아키텍트 역할

```
당신은 AI 시스템 아키텍트입니다.
모바일 앱과 AI 서비스를 통합하는 아키텍처를 설계해주세요.

현재 상황:
- 사용자 질문에 답변하는 챗봇 기능 필요
- 자사 문서(500개)와 FAQ(200개) 데이터 활용 필요
- iOS/Android 앱에서 사용
- 월간 활성 사용자 10만명, 일 평균 5만 쿼리 예상

요구사항:
1. 응답 지연시간 3초 이내 (P95)
2. 월 비용 $5,000 이하
3. 자사 데이터 보안 유지 (외부 학습 금지)
4. 99.9% 가용성

다음을 포함해 설명해주세요:
- 전체 시스템 아키텍처 다이어그램
- RAG 파이프라인 설계 (청킹 전략, 임베딩 모델)
- 모델 선택 기준과 Fallback 전략
- 캐싱 및 비용 최적화 방안
- 예상 비용 breakdown
```

### 기술 비교 분석

```
RAG vs Fine-tuning을 비교해주세요.

우리 상황:
- 도메인: 금융 상품 상담
- 데이터: 상품 설명서 100개, FAQ 500개
- 데이터 업데이트: 매주 5-10개 신규/변경
- 정확도 요구: 99% (금융 규제)
- 예산: 초기 구축 $10,000, 월 운영 $3,000

다음 관점에서 분석해주세요:
1. 구현 복잡도와 소요 기간
2. 데이터 업데이트 용이성
3. 응답 품질과 환각 위험
4. 비용 (초기 + 운영)
5. 확장성

결론으로 우리 상황에 맞는 추천과 구체적 이유를 설명해주세요.
```

---

## 산출물

이 레벨을 학습하며 다음 산출물을 만들어보세요:

### 1. AI 아키텍처 설계서

작성할 내용:
- 전체 시스템 아키텍처 다이어그램
- 컴포넌트별 기술 스택
- 데이터 흐름도
- 확장성/가용성 설계
- 보안 고려사항

### 2. RAG 파이프라인 구현

작성할 내용:
- 데이터 수집 및 전처리 코드
- 청킹 전략과 파라미터
- 임베딩 모델 선택 근거
- Vector DB 인덱싱 전략
- 검색 쿼리 최적화
- 프롬프트 템플릿

### 3. 비용 최적화 계획

작성할 내용:
- 현재 비용 breakdown
- 캐싱 전략 (Semantic Cache)
- 모델 티어링 계획
- 프롬프트 압축 방안
- 월간 비용 예측

### 4. MLOps 파이프라인

작성할 내용:
- CI/CD 워크플로우
- 모니터링 대시보드 설계
- 알림 규칙
- 드리프트 감지 기준
- 롤백 절차

---

## 모바일 AI 통합 체크리스트

```
[ ] LLM API 클라이언트 구현
    [ ] 스트리밍 응답 처리
    [ ] 타임아웃 및 재시도 로직
    [ ] 에러 핸들링 (Rate Limit, Server Error)

[ ] 캐싱 전략
    [ ] 로컬 응답 캐시 (LRU)
    [ ] Semantic Cache 연동 (선택)

[ ] 오프라인 대응
    [ ] On-device 모델 폴백 (Core ML / ML Kit)
    [ ] 캐시된 응답 활용
    [ ] 사용자 안내 메시지

[ ] 사용자 경험
    [ ] 로딩 인디케이터 (타이핑 애니메이션)
    [ ] 스트리밍 텍스트 렌더링
    [ ] 에러 상태 표시

[ ] 비용 관리
    [ ] 토큰 사용량 추적
    [ ] 일일/월간 한도 설정
    [ ] 비용 알림

[ ] 보안
    [ ] API 키 안전한 저장
    [ ] 입력 검증 (프롬프트 인젝션 방어)
    [ ] 민감 정보 필터링

[ ] 테스트
    [ ] 단위 테스트 (API 클라이언트)
    [ ] 통합 테스트 (E2E 응답)
    [ ] 성능 테스트 (지연시간)
```

---

## 참고 자료

### 공식 문서
- [OpenAI Documentation](https://platform.openai.com/docs)
- [Anthropic Claude Documentation](https://docs.anthropic.com)
- [Google Gemini API](https://ai.google.dev/docs)
- [LangChain Documentation](https://docs.langchain.com)
- [Pinecone Documentation](https://docs.pinecone.io)

### 학습 리소스
- [Hugging Face NLP Course](https://huggingface.co/learn/nlp-course)
- [DeepLearning.AI Short Courses](https://www.deeplearning.ai/short-courses)
- [LLM Bootcamp (Full Stack Deep Learning)](https://fullstackdeeplearning.com/llm-bootcamp)

### MLOps
- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [Made With ML - MLOps](https://madewithml.com)
- [Awesome MLOps](https://github.com/visenger/awesome-mlops)

### 커뮤니티
- [r/LocalLLaMA](https://reddit.com/r/LocalLLaMA)
- [AI Explained (YouTube)](https://youtube.com/@aiexplained-official)
- [Latent Space Podcast](https://www.latent.space)

---

## 다음 레벨

AI 시스템을 이해했다면, 이제 **Level 5: 아키텍처 설계**와 **Level 6: 테크 리드십**으로 나아갈 준비가 되었습니다.

```
Level 4: AI 시스템
      │
      ├──▶ Level 5: 아키텍처 설계
      │    └── 대규모 시스템 설계, 트레이드오프, 기술 의사결정
      │
      └──▶ Level 6: 테크 리드십
           └── 팀 리딩, 기술 전략, 조직 문화
```
